{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XwGM36jtcK-Z"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/nitishgopinath/Downloads/data_extraction_copy_2.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nitishgopinath/Downloads/data_extraction_copy_2.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nitishgopinath/Downloads/data_extraction_copy_2.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nitishgopinath/Downloads/data_extraction_copy_2.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import time\n",
        "import os\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puZSC_7hq7KU"
      },
      "outputs": [],
      "source": [
        "## !!! WE ARE NOT USING THIS !!!\n",
        "def blind_extraction(text):\n",
        "  for line in text:\n",
        "    if line == \"\\n\":\n",
        "      newLine = True\n",
        "      count +=1\n",
        "      if count ==2:\n",
        "          count = 0\n",
        "          print(list_1)\n",
        "          extracted_abstracts.append({\n",
        "              'PMID': list_1[5],\n",
        "              'doi': list_1[4],\n",
        "              'title': list_1[1],\n",
        "              'authors': list_1[2],\n",
        "              'text': list_1[3],\n",
        "          })\n",
        "          list_1 = []\n",
        "    else:\n",
        "        lineData = line\n",
        "        skip_append_flag = False\n",
        "\n",
        "        # Extract DOI as a seperate item\n",
        "        if(lineData.startswith(\"DOI:\")):\n",
        "          lineData = lineData.replace(\"DOI:\", \"\")\n",
        "\n",
        "        #Extract PMID as a seperate item\n",
        "        if(lineData.startswith(\"PMID:\")):\n",
        "          lineData = lineData.replace(\"PMID:\", \"\")\n",
        "          lineData = lineData.replace(\"[Indexed for MEDLINE]\", \"\")\n",
        "          list_1.append(lineData.rstrip().lstrip())\n",
        "          skip_append_flag = True\n",
        "\n",
        "        if(lineData.startswith(\"Copyright\")):\n",
        "          skip_append_flag = True\n",
        "\n",
        "        if(lineData.startswith(\"Author information:\")):\n",
        "          skip_append_flag = True\n",
        "        # Extract publication name --- future work\n",
        "        # Extract date published --- future work\n",
        "\n",
        "        if(not skip_append_flag):\n",
        "          if(newLine==False):\n",
        "            lineData = list_1[-1] +\" \"+ lineData.rstrip().lstrip()\n",
        "            list_1[-1] = lineData\n",
        "          else:\n",
        "            list_1.append(lineData.rstrip().lstrip())\n",
        "\n",
        "        count = 0\n",
        "        newLine=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NCZieJVXiLv"
      },
      "outputs": [],
      "source": [
        "abstract_data_dataframe = pd.DataFrame(columns=['PMID','doi', 'title', 'authors', 'text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoJnEGL5LYnh"
      },
      "outputs": [],
      "source": [
        "def checkCSVFile(file_name):\n",
        "  if not os.path.isfile(file_name):\n",
        "    # If the file doesn't exist, create it\n",
        "    with open(file_name, 'w', newline='') as csvfile:\n",
        "        # Create a CSV writer object\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "\n",
        "        # Write headers or any initial data to the file\n",
        "        headers = ['Column1', 'Column2', 'Column3']\n",
        "        csv_writer.writerow(headers)\n",
        "\n",
        "    print(f\"CSV file '{file_name}' has been created.\")\n",
        "  else:\n",
        "      print(f\"CSV file '{file_name}' already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1EqubfCMhmT"
      },
      "outputs": [],
      "source": [
        "global csv_abstract_filename\n",
        "csv_abstract_filename = \"/content/drive/MyDrive/NLPT(Abstract Data)/extracted_text_2.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwoCJpXLU_-K"
      },
      "outputs": [],
      "source": [
        "checkCSVFile(\"/content/drive/MyDrive/NLPT(Abstract Data)/failedPmids.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WqF32MSMe97"
      },
      "outputs": [],
      "source": [
        "checkCSVFile(csv_abstract_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toHAIYWrVLbO"
      },
      "outputs": [],
      "source": [
        "def writeFailedPmid(pmid):\n",
        "  failed_pmid_filename = \"/content/drive/MyDrive/NLPT(Abstract Data)/failedPmids.csv\"\n",
        "  #writing to csv file\n",
        "  with open(filename, 'a') as csvfile:\n",
        "    #creating a csv writer object\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "\n",
        "    # writing the data rows\n",
        "    csvwriter.writerows([[pmid]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tj9gDwrDAFeU"
      },
      "outputs": [],
      "source": [
        "def writeDataToCSVFile(data):\n",
        "  # name of csv file\n",
        "  filename = csv_abstract_filename\n",
        "  #writing to csv file\n",
        "  with open(filename, 'a') as csvfile:\n",
        "    #creating a csv writer object\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "\n",
        "    # writing the data rows\n",
        "    csvwriter.writerows([[data[\"pmid\"], data[\"doi\"], data[\"authors\"], data[\"title\"], data[\"text\"]]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ggh--Cx50yRj"
      },
      "outputs": [],
      "source": [
        "def recoverDataFromXML(XML_data):\n",
        "  extracted_data = {\n",
        "      \"pmid\":\"\",\n",
        "      \"doi\":\"\",\n",
        "      \"authors\":\"\",\n",
        "      \"title\":\"\",\n",
        "      \"text\":\"\"\n",
        "  }\n",
        "  tree = ET.ElementTree(ET.fromstring(XML_data.replace('\\n', '')))\n",
        "  for elem in tree.iter():\n",
        "    if(elem.tag == \"ArticleTitle\"):\n",
        "      extracted_data[\"title\"] = elem.text\n",
        "    if(elem.tag == \"ArticleId\"):\n",
        "      if(elem.attrib[\"IdType\"] == \"doi\"):\n",
        "        extracted_data[\"doi\"] = elem.text\n",
        "    if(elem.tag == \"AbstractText\"):\n",
        "      extracted_data[\"text\"] = elem.text\n",
        "    if(elem.tag == \"AuthorList\"):\n",
        "      author_list = []\n",
        "      for child in elem:\n",
        "        if(child.find(\"ForeName\") != None and child.find(\"LastName\") != None):\n",
        "          author_name=getattr(child.find(\"ForeName\"),\"text\")+\" \"+getattr(child.find(\"LastName\"),\"text\")\n",
        "          author_list.append(author_name)\n",
        "      extracted_data[\"authors\"] = author_list\n",
        "\n",
        "  return extracted_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaRBT8Mbx5MO"
      },
      "outputs": [],
      "source": [
        "def getAbstractData(pmID, testResponseMode = False) :\n",
        "  # api-endpoint\n",
        "  URL = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id={pmID}&retmode=XML&rettype=abstract\"\n",
        "\n",
        "  # sending get request and saving the response as response object\n",
        "  r = requests.get(url = URL)\n",
        "  print(r)\n",
        "  extractedText = None\n",
        "  if(testResponseMode):\n",
        "    print(r.text)\n",
        "  elif (testResponseMode==False and r.status_code == 200):\n",
        "    extractedText =  recoverDataFromXML(r.text)\n",
        "    extractedText[\"pmid\"] = pmID\n",
        "    writeDataToCSVFile(extractedText)\n",
        "  elif (testResponseMode==False and r.status_code != 200):\n",
        "    writeFailedPmid(pmID)\n",
        "  return extractedText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFo15xjHOmp-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myomPSqXOimj"
      },
      "outputs": [],
      "source": [
        "getAbstractData(35801624, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rda-rV0yjBV"
      },
      "outputs": [],
      "source": [
        "\n",
        "extracted_text = getAbstractData(\"36736583\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLh6-onjRU_5"
      },
      "outputs": [],
      "source": [
        "file = open(f\"/content/drive/MyDrive/NLPT(Abstract Data)/abstracts-original/abstract-intelligen-set (2).txt\", 'r', encoding=\"utf-8\")\n",
        "text = file.readlines()\n",
        "count = 0\n",
        "pmid_extracted_counter = 0\n",
        "api_rate_limiter = 0\n",
        "pmid_val = \"\"\n",
        "chunk_abstracts = []\n",
        "newLine = True\n",
        "for line in text:\n",
        "  if line == \"\\n\":\n",
        "    newLine = True\n",
        "    count +=1\n",
        "    if count ==2:\n",
        "      count = 0\n",
        "      if(pmid_val != \"\"):\n",
        "        pmid_extracted_counter += 1\n",
        "        if(pmid_extracted_counter >= 1566):\n",
        "          print(pmid_extracted_counter)\n",
        "          extracted_text = getAbstractData(pmid_val)\n",
        "          api_rate_limiter += 1\n",
        "          if(api_rate_limiter == 3):\n",
        "            time.sleep(1)\n",
        "            api_rate_limiter = 0\n",
        "        #abstract_data_dataframe = pd.concat([abstract_data_dataframe, pd.DataFrame(extracted_text)], axis=0, ignore_index=True)\n",
        "      list_1 = []\n",
        "  else:\n",
        "    count = 0\n",
        "    lineData = line\n",
        "    #Extract PMID as a seperate item\n",
        "    if(lineData.startswith(\"PMID:\")):\n",
        "      lineData = lineData.replace(\"PMID:\", \"\")\n",
        "      lineData = lineData.replace(\"[Indexed for MEDLINE]\", \"\")\n",
        "      pmid_val = lineData.rstrip().lstrip()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2xMkvK2wCiD"
      },
      "outputs": [],
      "source": [
        "len(chunk_abstracts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP_xF-nEATSq"
      },
      "outputs": [],
      "source": [
        "def getPMIDs ():\n",
        "  chunk_abstracts = []\n",
        "  for i in range(0,1):\n",
        "      file = open(f\"/content/drive/MyDrive/NLPT(Abstract Data)/abstracts-original/abstract-intelligen-set (1).txt\", 'r', encoding=\"utf-8\")\n",
        "      text = file.readlines()\n",
        "      count = 0\n",
        "      pmid_val = \"\"\n",
        "      chunk_abstracts = []\n",
        "      newLine = True\n",
        "      for line in text:\n",
        "        if line == \"\\n\":\n",
        "          newLine = True\n",
        "          count +=1\n",
        "          if count ==2:\n",
        "            count = 0\n",
        "            if(pmid_val != \"\"):\n",
        "              chunk_abstracts.append(pmid_val)\n",
        "              #abstract_data_dataframe = pd.concat([abstract_data_dataframe, pd.DataFrame(extracted_text)], axis=0, ignore_index=True)\n",
        "            list_1 = []\n",
        "        else:\n",
        "          count = 0\n",
        "          lineData = line\n",
        "          #Extract PMID as a seperate item\n",
        "          if(lineData.startswith(\"PMID:\")):\n",
        "            lineData = lineData.replace(\"PMID:\", \"\")\n",
        "            lineData = lineData.replace(\"[Indexed for MEDLINE]\", \"\")\n",
        "            pmid_val = lineData.rstrip().lstrip()\n",
        "  return chunk_abstracts\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI2HMg4_AplQ"
      },
      "outputs": [],
      "source": [
        "chunk_abstracts = getPMIDs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGzWfjttBVS6"
      },
      "outputs": [],
      "source": [
        "len(chunk_abstracts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4lVJ8j3BrKW"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/NLPT(Abstract Data)/extracted_text.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGqPeNFCBvZc"
      },
      "outputs": [],
      "source": [
        "df.columns = ['PMID','doi', 'title', 'authors', 'text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFy_qD7oCXus"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W_wVlFJCaBl"
      },
      "outputs": [],
      "source": [
        "read_pmids = df[\"PMID\"].astype(str).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUYTeKqlC8OG"
      },
      "outputs": [],
      "source": [
        "read_pmids[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mbs_srUCii5"
      },
      "outputs": [],
      "source": [
        "def find_missing_elements(arr1, arr2):\n",
        "    missing_elements = []\n",
        "    # Convert arrays to sets for faster comparison\n",
        "    set1 = set(arr1)\n",
        "    set2 = set(arr2)\n",
        "\n",
        "    # Find elements in arr1 that are not in arr2\n",
        "    missing_elements = list(set1 - set2)\n",
        "\n",
        "    return missing_elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lacd8oZCwrk"
      },
      "outputs": [],
      "source": [
        "missed_pmids = find_missing_elements(chunk_abstracts,read_pmids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuIMGLB6C467"
      },
      "outputs": [],
      "source": [
        "len(missed_pmids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN051swDDRFx"
      },
      "outputs": [],
      "source": [
        "def addMissedPmidsToCSV(missed_pmids):\n",
        "  api_rate_limiter = 0\n",
        "  for i in range(0, len(missed_pmids)):\n",
        "    print(i)\n",
        "    extracted_text = getAbstractData(missed_pmids[i])\n",
        "    api_rate_limiter += 1\n",
        "    if(api_rate_limiter == 3):\n",
        "      time.sleep(1)\n",
        "      api_rate_limiter = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZk7EBmaEOML"
      },
      "outputs": [],
      "source": [
        "addMissedPmidsToCSV(missed_pmids)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
