{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uWNvIiqzbvUg"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import spacy\n",
        "import logging  # Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file name of the CSV file to be read\n",
        "file_name = \"extracted_text_1.csv\"\n",
        "\n",
        "# Read the CSV file into a DataFrame, skipping any bad lines\n",
        "df = pd.read_csv(file_name, on_bad_lines='skip')  # Load the data\n",
        "\n",
        "# Set the column names of the DataFrame explicitly\n",
        "df.columns = ['PMID', 'DOI', 'Authors', 'Title', 'Content']\n",
        "\n",
        "# Display the first 10 rows of the DataFrame for a quick overview\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "KJTA3THPbybZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replacing abbreviations"
      ],
      "metadata": {
        "id": "iCvb3EOncPlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def replace_with_dict(sentence, my_dict):\n",
        "    for key, value in my_dict.items():\n",
        "        # Replace the key in the sentence with the value\n",
        "        sentence = re.sub(r'\\b' + re.escape(key) + r'\\b', value, sentence)\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "WAUbtpujb8mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize two empty lists\n",
        "list1 = []\n",
        "list2 = []\n",
        "\n",
        "# Define a regex pattern that matches a string of non-digit characters\n",
        "pattern = r'^\\D+$'\n",
        "\n",
        "# Iterate over each sentence in the 'Content' column of the DataFrame\n",
        "for sentence in df[\"Content\"]:\n",
        "    # Initialize an empty dictionary for each sentence\n",
        "    my_dict = {}\n",
        "\n",
        "    # Temporary string to construct a phrase\n",
        "    sent = \"\"\n",
        "\n",
        "    # Convert the sentence to a string and remove periods and commas\n",
        "    sentence = str(sentence)\n",
        "    sentence = re.sub(r'[.,]', '', sentence)\n",
        "\n",
        "    # Split the sentence into a list of words\n",
        "    text_list = sentence.split()\n",
        "\n",
        "    # Check if the sentence contains an opening parenthesis\n",
        "    if \"(\" in sentence:\n",
        "        # Iterate over each word in the sentence\n",
        "        for i in range(len(text_list)):\n",
        "            # Check if the word meets several conditions:\n",
        "            # 1. Starts with an opening parenthesis\n",
        "            # 2. Is less than 8 characters and more than 3 characters long\n",
        "            # 3. Contains a closing parenthesis\n",
        "            # 4. Matches the specified pattern (non-digit characters)\n",
        "            if (text_list[i][0] == \"(\" and len(text_list[i]) < 8 and\n",
        "                \")\" in text_list[i] and len(text_list[i]) > 3 and\n",
        "                re.match(pattern, text_list[i])):\n",
        "                # Look up to 4 words before the current word\n",
        "                for k in range(i-2, i-5, -1):\n",
        "                    try:\n",
        "                        # Check if the first character of a previous word matches\n",
        "                        # the second character of the current word (case-insensitive)\n",
        "                        if text_list[k][0].lower() == text_list[i][1].lower():\n",
        "                            # Construct a phrase from the words between these two points\n",
        "                            for p in range(k, i):\n",
        "                                sent += text_list[p] + \" \"\n",
        "\n",
        "                            # Add the phrase to list1 if it's not already present\n",
        "                            if sent not in list1:\n",
        "                                list1.append(sent)\n",
        "                                # Add an entry to the dictionary with the key being\n",
        "                                # the current word stripped of parentheses\n",
        "                                my_dict[text_list[i][1:len(text_list[i]) - 1]] = sent\n",
        "                            # Reset the temporary string\n",
        "                            sent = \"\"\n",
        "                            break\n",
        "                    except:\n",
        "                        # Handle any exceptions that occur (e.g., index errors)\n",
        "                        pass\n",
        "\n",
        "    # Replace words in the sentence based on the dictionary and add to list2\n",
        "    modified_sentence = replace_with_dict(sentence, my_dict)\n",
        "    list2.append(modified_sentence)\n",
        "\n",
        "# Add the modified sentences as a new column 'abr' in the DataFrame\n",
        "df[\"abr\"] = pd.Series(list2)"
      ],
      "metadata": {
        "id": "kd9kFuxYcBu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using SpaCy to preprocess the text. Performing the following steps:\n",
        "\n",
        "lowercase the words\n",
        "remove the stopwords and single characters\n",
        "use regex to remove non-alphabetic characters (anything that is not a number or alphabet including punctuations), in other words only keep \"a\" to \"z\" and digits.\n",
        "remove lines that have less than 4 words, since they cannot contribute much to the training process."
      ],
      "metadata": {
        "id": "bixY6_wAcV7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the small English model from spaCy, disabling tagger, parser, and NER for efficiency\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
        "\n",
        "# Load the set of English stopwords\n",
        "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Convert each quote to lowercase for standardization\n",
        "df[\"cleaned\"] = pd.Series(str(quote).lower() for quote in df[\"abr\"])\n",
        "\n",
        "list0 = []\n",
        "for sentence in df[\"cleaned\"]:\n",
        "    # Iterate through each stopword\n",
        "    for word in stopwords:\n",
        "        # If the stopword contains an apostrophe, remove it from the sentence\n",
        "        if \"'\" in word:\n",
        "            sentence = re.sub(re.escape(word) + r'\\b', '', sentence, flags=re.IGNORECASE)\n",
        "        else:\n",
        "            # Else, remove the stopword ensuring it is a whole word (`\\b` is a word boundary)\n",
        "            sentence = re.sub(r'\\b' + re.escape(word) + r'\\b', '', sentence, flags=re.IGNORECASE)\n",
        "    list0.append(sentence)\n",
        "\n",
        "# Update the 'cleaned' column with the sentences from which stopwords have been removed\n",
        "df[\"cleaned\"] = pd.Series(list0)\n",
        "\n",
        "# Remove all characters except letters, numbers, and whitespaces\n",
        "df[\"cleaned\"] = pd.Series([re.sub(r'[^a-zA-Z0-9\\s\\(\\)]', \"\", quote) for quote in df[\"cleaned\"]])\n",
        "\n",
        "# Remove standalone single letters from the sentences\n",
        "df[\"cleaned\"] = pd.Series([re.sub(r\"\\b[a-zA-Z]\\b\", \"\", sentence) for sentence in df[\"cleaned\"]])\n",
        "\n",
        "# Replace multiple consecutive spaces with a single space and trim leading/trailing spaces\n",
        "df[\"cleaned\"] = pd.Series([re.sub(r'\\s+', ' ', text).strip() for text in df[\"cleaned\"]])\n",
        "\n",
        "# Function to count the number of words in a sentence\n",
        "def word_count(sentence):\n",
        "    return len(sentence.split())\n",
        "\n",
        "# Filter the DataFrame to only include sentences with 4 or more words\n",
        "filtered_df = df[df[\"cleaned\"].apply(word_count) >= 4]\n",
        "print(filtered_df)\n",
        "\n",
        "# Create a list of sentences from the 'cleaned' column of the filtered DataFrame\n",
        "quotes = [sentence for sentence in filtered_df[\"cleaned\"]]  # Save all the lines"
      ],
      "metadata": {
        "id": "XsEovnkdcFML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df[\"abr\"]"
      ],
      "metadata": {
        "id": "19RCXFDCcIbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving in a new file preprocessed code"
      ],
      "metadata": {
        "id": "tCPxHZQSc3v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(f'file_1.csv', index=False)"
      ],
      "metadata": {
        "id": "0vlUb0gecK8E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}