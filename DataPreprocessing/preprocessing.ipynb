{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWNvIiqzbvUg"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import spacy\n",
        "import logging  # Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = f\"extracted_text_1.csv\"\n",
        "df = pd.read_csv(file_name, on_bad_lines='skip') ### Load the data ####\n",
        "### filter out columns ###\n",
        "df.columns = ['PMID', 'DOI', 'Authors', 'Title','Content']\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "KJTA3THPbybZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replacing abbreviations"
      ],
      "metadata": {
        "id": "iCvb3EOncPlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def replace_with_dict(sentence, my_dict):\n",
        "    for key, value in my_dict.items():\n",
        "        # Replace the key in the sentence with the value\n",
        "        sentence = re.sub(r'\\b' + re.escape(key) + r'\\b', value, sentence)\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "WAUbtpujb8mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = []\n",
        "list2 = []\n",
        "pattern = r'^\\D+$'\n",
        "for sentence in df[\"Content\"]:\n",
        "    my_dict = {}\n",
        "    sent = \"\"\n",
        "    # print(sentence)\n",
        "    sentence = str(sentence)\n",
        "    sentence = re.sub(r'[.,]', '', sentence)\n",
        "    text_list = sentence.split()\n",
        "    if \"(\" in sentence:\n",
        "      for i in range(len(text_list)):\n",
        "        elem = text_list[i][0]\n",
        "        if text_list[i][0]==\"(\" and len(text_list[i]) <8 and \")\" in text_list[i] and len(text_list[i]) >3 and re.match(pattern, text_list[i]):\n",
        "          for k in range(i-2,i-5,-1):\n",
        "            try:\n",
        "                if text_list[k][0].lower() == text_list[i][1].lower():\n",
        "                  for p in range(k,i):\n",
        "                    sent += text_list[p]+\" \"\n",
        "                  if sent not in list1:\n",
        "                      list1.append(sent)\n",
        "                      my_dict[text_list[i][1:len(text_list[i])-1]] = sent\n",
        "                  sent = \"\"\n",
        "                  break\n",
        "            except:\n",
        "              pass\n",
        "    modified_sentence = replace_with_dict(sentence, my_dict)\n",
        "    list2.append(modified_sentence)\n",
        "df[\"abr\"] = pd.Series(list2)"
      ],
      "metadata": {
        "id": "kd9kFuxYcBu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using SpaCy to preprocess the text. Performing the following steps:\n",
        "\n",
        "lowercase the words\n",
        "remove the stopwords and single characters\n",
        "use regex to remove non-alphabetic characters (anything that is not a number or alphabet including punctuations), in other words only keep \"a\" to \"z\" and digits.\n",
        "remove lines that have less than 4 words, since they cannot contribute much to the training process."
      ],
      "metadata": {
        "id": "bixY6_wAcV7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\",\"ner\"])\n",
        "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "df[\"cleaned\"] = pd.Series( str(quote).lower() for quote in df[\"abr\"])\n",
        "list0 = []\n",
        "for sentence in df[\"cleaned\"]:\n",
        "    for word in stopwords:\n",
        "        if \"'\" in word:\n",
        "            sentence = re.sub(re.escape(word) + r'\\b' , '', sentence, flags=re.IGNORECASE)\n",
        "        else:\n",
        "            sentence = re.sub(r'\\b' + re.escape(word) + r'\\b' , '', sentence, flags=re.IGNORECASE)\n",
        "    list0.append(sentence)\n",
        "df[\"cleaned\"] = pd.Series(list0)\n",
        "df[\"cleaned\"] = pd.Series([re.sub(r'[^a-zA-Z0-9\\s\\(\\)]', \"\", quote) for quote in df[\"cleaned\"]])# lowercase and remove non-alphabetic characters\n",
        "df[\"cleaned\"] = pd.Series([re.sub(r\"\\b[a-zA-Z]\\b\", \"\", sentence) for sentence in df[\"cleaned\"]])\n",
        "df[\"cleaned\"] = pd.Series([re.sub(r'\\s+', ' ', text).strip() for text in df[\"cleaned\"]])\n",
        "def word_count(sentence):\n",
        "    return len(sentence.split())\n",
        "\n",
        "filtered_df = df[df[\"cleaned\"].apply(word_count) >= 4]\n",
        "print(filtered_df)\n",
        "\n",
        "quotes =[sentence for sentence in filtered_df[\"cleaned\"]] # to save all the lines\n",
        "# print(quotes)"
      ],
      "metadata": {
        "id": "XsEovnkdcFML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df[\"abr\"]"
      ],
      "metadata": {
        "id": "19RCXFDCcIbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving in a new file preprocessed code"
      ],
      "metadata": {
        "id": "tCPxHZQSc3v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(f'file_{num}.csv', index=False)"
      ],
      "metadata": {
        "id": "0vlUb0gecK8E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}