{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t65FnCJ-QzB8"
      },
      "outputs": [],
      "source": [
        "%pip install sentence_transformers -q\n",
        "%pip install langchain -q\n",
        "%pip install langchain-openai -q\n",
        "%pip install google-cloud-aiplatform -q\n",
        "%pip install opensearch-py -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "from opensearchpy import OpenSearch, helpers\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "z9as2OyERx5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenSearch(\n",
        "   hosts=[\"https://admin:2NCbjLJWWzIFw@ec2-34-207-194-37.compute-1.amazonaws.com:9200/\"],\n",
        "    http_compress=True,\n",
        "    use_ssl=True,\n",
        "    verify_certs=False,\n",
        "    ssl_assert_hostname=False,\n",
        "    ssl_show_warn=False,\n",
        ")"
      ],
      "metadata": {
        "id": "7A62qwIjR6aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INDEX_NAME = \"inlpt-without-chunking\""
      ],
      "metadata": {
        "id": "defe_rWqTIYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding model\n",
        "model_miniLM = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "LpuC9DwbTL8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "tiZYfXspTQBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This authentication is only for colab\n",
        "# If you are setting this up locally on your mac or AWS, you simply install gcloud cli and then run `gcloud auth login` one time on your terminal.\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth as google_auth\n",
        "\n",
        "    google_auth.authenticate_user()"
      ],
      "metadata": {
        "id": "SAVeoFFSTTK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'gemini-1.0-pro'\n",
        "project_id = 'my-first-project' # TODO: fill this\n",
        "location = 'us-central1'\n",
        "generation_config = {\n",
        "    'max_output_tokens': 2048,\n",
        "    'temperature': 0.2,\n",
        "    'top_p': 0.85,\n",
        "    'top_k': 40\n",
        "}"
      ],
      "metadata": {
        "id": "dhFkXPSJTcMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vertexai.preview.generative_models import GenerativeModel\n",
        "from google.cloud import aiplatform\n",
        "import vertexai"
      ],
      "metadata": {
        "id": "TpmCyv51TiZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise client\n",
        "vertexai.init(project=project_id, location=location)\n",
        "model = GenerativeModel(model_name, generation_config=generation_config)"
      ],
      "metadata": {
        "id": "mthRpEvbTmxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt template\n",
        "prompt = '''You are an expert on life sciences and biomedical topics. Your task is to use the context below and answer the question. Do not make up information.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question} Justify your response using the context and support with examples from the context.\n",
        "\n",
        "Response:\n",
        "'''"
      ],
      "metadata": {
        "id": "vioIh_OFTpp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'Has Augmented intelligence become the focus of clinical interest?' # @param {'type' : 'string'}"
      ],
      "metadata": {
        "id": "hbhLr_dJTtYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Are there developmental delays in children with ADHD\""
      ],
      "metadata": {
        "id": "Hmc1pCEITwOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLVDhTiOcMze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Is the psychological profile of GERD patients, especially those without hiatal hernia, considered in the evaluation of clinical symptoms and outcomes of antireflux surgery? [Yes or No]\""
      ],
      "metadata": {
        "id": "vOQ5oavScLpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question  = \"List the instruments used for the clinical examination and evaluation of GERD patients who had undergone laparoscopic antireflux surgery.\""
      ],
      "metadata": {
        "id": "wXc-_me0fLst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create search query\n",
        "query = {\n",
        "    \"size\": 5,\n",
        "    \"query\": {\"knn\": {\"embedding\": {\"vector\": model_miniLM.encode(question), \"k\": 10}}},\n",
        "    \"_source\": False,\n",
        "    \"fields\": [\"id\",\"doi\",\"authors\", \"text\"],\n",
        "}"
      ],
      "metadata": {
        "id": "4l2H3UGbT0cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collate search results to a single string\n",
        "results = client.search(body=query, index=INDEX_NAME)\n",
        "\n",
        "results = results['hits']['hits']\n",
        "\n",
        "context = \"\"\n",
        "for row in results:\n",
        "  value = row['fields']['text'][0]\n",
        "  context += value + \"\\n\" + \"- - - - - \"*10 + \"\\n\"\n",
        "\n",
        "print(context)"
      ],
      "metadata": {
        "id": "_jugAFD1UJXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Format and use prompt to generate response\n",
        "response = model.generate_content([prompt.format(\n",
        "    context = context,\n",
        "    question = question\n",
        ")])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "aVa_ddQ5UNHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install gradio"
      ],
      "metadata": {
        "id": "wh5vMVCLVFA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createInput(question, chat_history):\n",
        "  # Create search query\n",
        "  query = {\n",
        "      \"size\": 30,\n",
        "      \"query\": {\"knn\": {\"embedding\": {\"vector\": model_miniLM.encode(question), \"k\": 10}}},\n",
        "      \"_source\": False,\n",
        "      \"fields\": [\"id\",\"doi\",\"authors\", \"text\"],\n",
        "  }\n",
        "  results = client.search(body=query, index=INDEX_NAME)\n",
        "\n",
        "  results = results['hits']['hits']\n",
        "\n",
        "  context = \"\"\n",
        "  for row in results:\n",
        "    value = row['fields']['text'][0]\n",
        "    context += value + \"\\n\" + \"- - - - - \"*10 + \"\\n\"\n",
        "\n",
        "  response = model.generate_content([prompt.format(\n",
        "    context = context,\n",
        "    question = question\n",
        "  )])\n",
        "  chat_history.append((question,response.text))\n",
        "  return \"\", chat_history\n"
      ],
      "metadata": {
        "id": "rJk0ukBrW-6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=createInput,\n",
        "    inputs=[\"text\"],\n",
        "    outputs=[\"text\"],\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "xQcF4oD9VMML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    with gr.Row():\n",
        "      clear = gr.ClearButton([msg, chatbot])\n",
        "      submit = gr.Button(\"Submit\")\n",
        "    msg.submit(createInput, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "7GdW65wqX9O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "jNLgiz4ZlqCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Please tell me some key importants about data science\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EpG6Ov0kluOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are the professor of Bio Science.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ],\n",
        ")\n"
      ],
      "metadata": {
        "id": "Jglm74UFlR2e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}